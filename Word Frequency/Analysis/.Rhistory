p_list = seq(-50, 150, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
#Find thresholds
for (p in p_list){
out[p+51,] = find.interp.thresholds(p/100, def.limit)
}
df = data.frame(out)
colnames(df) = c('asian','white','black','hispanic')
df$p = p_list
df = df %>% gather(key = 'race', value = 'FICO', 1:4)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race, linetype = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral"))+
ggtitle(paste("Def rate = ", def.limit, "\nBase rates = ", mu_type ))
#Find approval percent
for (p in p_list){
for(i in 1:length(race_means))
out[p+1,i] = round((1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100,0)
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
colnames(df) = c('asian','white','black','hispanic')
out.json = toJSON(df, pretty = T)
write(out.json, "./FICOTest.json")
out.json
head(out.json,10)
df$mu = rowMeans(df[,1:4])
colnames(df) = c('asian','white','black','hispanic', 'mu')
df$p = p_list
df = df %>% gather(key = 'race', value = 'FICO', 1:5)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen",'black',"coral"))+
ggtitle(paste("Def rate = ", def.limit, "\nBase rates = ", mu_type ))+
ylab('Approval %')
#Plot FICO by p
p_list = seq(-50, 100, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
#Find thresholds
for (p in p_list){
out[p+51,] = find.interp.thresholds(p/100, def.limit)
}
df = data.frame(out)
colnames(df) = c('asian','white','black','hispanic')
df$p = p_list
df = df %>% gather(key = 'race', value = 'FICO', 1:4)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race, linetype = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral"))+
ggtitle(paste("Def rate = ", def.limit, "\nBase rates = ", mu_type ))
#Find approval percent
for (p in p_list){
for(i in 1:length(race_means))
out[p+1,i] = round((1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100,0)
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
colnames(df) = c('asian','white','black','hispanic')
out.json = toJSON(df, pretty = T)
write(out.json, "./FICOTest.json")
df$mu = rowMeans(df[,1:4])
colnames(df) = c('asian','white','black','hispanic', 'mu')
df$p = p_list
df = df %>% gather(key = 'race', value = 'FICO', 1:5)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen",'black',"coral"))+
ggtitle(paste("Def rate = ", def.limit, "\nBase rates = ", mu_type ))+
ylab('Approval %')
#Plot FICO by p
p_list = seq(-50, 150, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
#Find approval percent
for (p in p_list){
for(i in 1:length(race_means))
out[p+51,i] = round((1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100,0)
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
colnames(df) = c('asian','white','black','hispanic')
out.json = toJSON(df, pretty = T)
write(out.json, "./FICOTest.json")
df$mu = rowMeans(df[,1:4])
colnames(df) = c('asian','white','black','hispanic', 'mu')
df$p = p_list
df = df %>% gather(key = 'race', value = 'FICO', 1:5)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen",'black',"coral"))+
ggtitle(paste("Def rate = ", def.limit, "\nBase rates = ", mu_type ))+
ylab('Approval %')
#######################
#Define known values:
#######################
library(tidyverse)
library(patchwork)
library(jsonlite)
def.limit = 0.1
# base_rates
race_rates = c('asian'=0.06, 'white'=0.61, 'black'=0.14, 'hispanic'=0.19)
race_rates = c('asian'=0.25, 'white'=0.25, 'black'=0.25, 'hispanic'=0.25) #equal base rates
# means
race_means = c('asian'=750, 'white'=700, 'black'=450, 'hispanic'=500) #"extreme differences"
mu_type = 'ALTERED: A:750, W:700, B:450, H:500'
race_sds = c('asian'=115, 'white'=118, 'black'=118, 'hispanic'=120)
# pdf of fico score given the fico truncation.
dtnorm = function(x, m, s){
dnorm(x, m, s) / (pnorm(850, m, s) - pnorm(300, m, s))
}
# default-rate for fico
def_rate_fico = function(x){(1-1/(1+exp(-.016*(x-550))))}
# default rate for threshold, mu, sd
default_rate = function(threshold, m, s){
integrate(function(x){
dtnorm(x,m,s)*def_rate_fico(x)
},
threshold,850)$val
}
# total default rate with baserates
default_rate_total = function(thresholds){
dr = purrr::pmap_dbl(data.frame(threshold = thresholds, m = race_means, s = race_sds),
default_rate)
sum(dr*race_rates)/sum(race_rates) # in case we dont have it sum to 1
}
# find constant thresholds
find.constant.thresholds = function(def.limit){
t = uniroot(function(t){
default_rate_total(rep(t, 4))-def.limit
},
lower=300,
upper=850)$root
rep(t, 4)
}
# find constant conditional probability
find.equal.thresholds = function(def.limit){
p = uniroot(function(p){
default_rate_total(qnorm(1-p, race_means, race_sds))-def.limit},
lower=0.001,
upper=0.999)$root
qnorm(1-p, race_means, race_sds)
}
# find threshold for interpolated p
thresholds_p1 = find.equal.thresholds(def.limit)
deltas = thresholds_p1 - mean(thresholds_p1)
find.interp.thresholds = function(p, def.limit){
mu = uniroot(function(mu){
thresholds = deltas*p + mu
default_rate_total(thresholds)-def.limit
}, lower=300,
upper=850)$root
mu+deltas*p
}
#Plot FICO by p
p_list = seq(-50, 150, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
#Find thresholds
for (p in p_list){
out[p+51,] = find.interp.thresholds(p/100, def.limit)
}
df = data.frame(out)
colnames(df) = c('asian','white','black','hispanic')
df$p = p_list
df = df %>% gather(key = 'race', value = 'FICO', 1:4)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race, linetype = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral"))+
ggtitle(paste("Def rate = ", def.limit, "\nBase rates = ", mu_type ))
#Find approval percent
for (p in p_list){
for(i in 1:length(race_means))
out[p+51,i] = round((1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100,0)
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
df$mu = rowMeans(df[,1:4])
colnames(df) = c('asian','white','black','hispanic', 'mu')
out.json = toJSON(df, pretty = T)
write(out.json, "./FICOTest.json")
df$p = p_list
df = df %>% gather(key = 'race', value = 'FICO', 1:5)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen",'black',"coral"))+
ggtitle(paste("Def rate = ", def.limit, "\nBase rates = ", mu_type ))+
ylab('Approval %')
def.limit = 0.1
# base_rates
race_rates = c('asian'=0.06, 'white'=0.61, 'black'=0.14, 'hispanic'=0.19)
race_rates = c('asian'=0.25, 'white'=0.25, 'black'=0.25, 'hispanic'=0.25) #equal base rates
# means
race_means = c('asian'=750, 'white'=700, 'black'=450, 'hispanic'=500) #"extreme differences"
mu_type = 'ALTERED: A:750, W:700, B:450, H:500'
race_sds = c('asian'=115, 'white'=118, 'black'=118, 'hispanic'=120)
# pdf of fico score given the fico truncation.
dtnorm = function(x, m, s){
dnorm(x, m, s) / (pnorm(850, m, s) - pnorm(300, m, s))
}
# default-rate for fico
def_rate_fico = function(x){(1-1/(1+exp(-.016*(x-550))))}
# default rate for threshold, mu, sd
default_rate = function(threshold, m, s){
integrate(function(x){
dtnorm(x,m,s)*def_rate_fico(x)
},
threshold,850)$val
}
# total default rate with baserates
default_rate_total = function(thresholds){
dr = purrr::pmap_dbl(data.frame(threshold = thresholds, m = race_means, s = race_sds),
default_rate)
sum(dr*race_rates)/sum(race_rates) # in case we dont have it sum to 1
}
# find constant thresholds
find.constant.thresholds = function(def.limit){
t = uniroot(function(t){
default_rate_total(rep(t, 4))-def.limit
},
lower=300,
upper=850)$root
rep(t, 4)
}
# find constant conditional probability
find.equal.thresholds = function(def.limit){
p = uniroot(function(p){
default_rate_total(qnorm(1-p, race_means, race_sds))-def.limit},
lower=0.001,
upper=0.999)$root
qnorm(1-p, race_means, race_sds)
}
# find threshold for interpolated p
thresholds_p1 = find.equal.thresholds(def.limit)
deltas = thresholds_p1 - mean(thresholds_p1)
find.interp.thresholds = function(p, def.limit){
mu = uniroot(function(mu){
thresholds = deltas*p + mu
default_rate_total(thresholds)-def.limit
}, lower=300,
upper=850)$root
mu+deltas*p
}
#Plot FICO by p
p_list = seq(50, 250, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
#Find thresholds
for (p in p_list){
out[p+51,] = find.interp.thresholds(p/100, def.limit)
}
df = data.frame(out)
colnames(df) = c('asian','white','black','hispanic')
#Find thresholds
for (p in p_list){
out[p-49,] = find.interp.thresholds(p/100, def.limit)
}
df = data.frame(out)
colnames(df) = c('asian','white','black','hispanic')
df$p = p_list
df = df %>% gather(key = 'race', value = 'FICO', 1:4)
theme_set(theme_minimal())
#######################
#Define known values:
#######################
library(tidyverse)
library(patchwork)
library(jsonlite)
df = df %>% gather(key = 'race', value = 'FICO', 1:4)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race, linetype = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral"))+
ggtitle(paste("Def rate = ", def.limit, "\nBase rates = ", mu_type ))
#Find approval percent
for (p in p_list){
for(i in 1:length(race_means))
out[p-49,i] = round((1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100,0)
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
df$mu = rowMeans(df[,1:4])
colnames(df) = c('asian','white','black','hispanic', 'mu')
out.json = toJSON(df, pretty = T)
write(out.json, "./FICOTest.json")
df$p = p_list
df = df %>% gather(key = 'race', value = 'FICO', 1:5)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen",'black',"coral"))+
ggtitle(paste("Def rate = ", def.limit, "\nBase rates = ", mu_type ))+
ylab('Approval %')
#Plot FICO by p
p_list = seq(-150, 50, by = 1)
#Find approval percent
for (p in p_list){
for(i in 1:length(race_means))
out[p+151,i] = round((1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100,0)
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
df$mu = rowMeans(df[,1:4])
colnames(df) = c('asian','white','black','hispanic', 'mu')
out.json = toJSON(df, pretty = T)
write(out.json, "./FICOTest.json")
df$p = p_list
df = df %>% gather(key = 'race', value = 'FICO', 1:5)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen",'black',"coral"))+
ggtitle(paste("Def rate = ", def.limit, "\nBase rates = ", mu_type ))+
ylab('Approval %')
#Trump
dfTrump = read.csv('trump.csv')
setwd("~/Documents/Year 1/Research/Word Frequency/Analysis")
#Trump
dfTrump = read.csv('trump.csv')
ggplot(data = dfTrump, aes(x = day, y = lpobs))+
geom_line(lwd = .2)+
theme_bw() +
geom_vline(xintercept = 348,  color='red', linetype = 'dashed')+
ggtitle('Trump')+ xlab('Day') +ylab('Observed Log Probability')+
annotate(geom="text", x=550, y=-8.8, label="Election Day 2016")+
theme(plot.title = element_text(hjust = 0.5))
ggsave(filename = "./Trump.pdf",height = 3, width = 4)
#######################
#Define known values:
#######################
library(tidyverse)
library(patchwork)
library(jsonlite)
def.limit = 0.1
# base_rates
race_rates = c('asian'=0.06, 'white'=0.61, 'black'=0.14, 'hispanic'=0.19)
race_rates = c('asian'=0.25, 'white'=0.25, 'black'=0.25, 'hispanic'=0.25) #equal base rates
# means
race_means = c('asian'=750, 'white'=700, 'black'=450, 'hispanic'=500) #"extreme differences"
mu_type = 'ALTERED: A:750, W:700, B:450, H:500'
race_sds = c('asian'=115, 'white'=118, 'black'=118, 'hispanic'=120)
# pdf of fico score given the fico truncation.
dtnorm = function(x, m, s){
dnorm(x, m, s) / (pnorm(850, m, s) - pnorm(300, m, s))
}
# default-rate for fico
def_rate_fico = function(x){(1-1/(1+exp(-.016*(x-550))))}
# default rate for threshold, mu, sd
default_rate = function(threshold, m, s){
integrate(function(x){
dtnorm(x,m,s)*def_rate_fico(x)
},
threshold,850)$val
}
# total default rate with baserates
default_rate_total = function(thresholds){
dr = purrr::pmap_dbl(data.frame(threshold = thresholds, m = race_means, s = race_sds),
default_rate)
sum(dr*race_rates)/sum(race_rates) # in case we dont have it sum to 1
}
# find constant thresholds
find.constant.thresholds = function(def.limit){
t = uniroot(function(t){
default_rate_total(rep(t, 4))-def.limit
},
lower=300,
upper=850)$root
rep(t, 4)
}
# find constant conditional probability
find.equal.thresholds = function(def.limit){
p = uniroot(function(p){
default_rate_total(qnorm(1-p, race_means, race_sds))-def.limit},
lower=0.001,
upper=0.999)$root
qnorm(1-p, race_means, race_sds)
}
# find threshold for interpolated p
thresholds_p1 = find.equal.thresholds(def.limit)
deltas = thresholds_p1 - mean(thresholds_p1)
find.interp.thresholds = function(p, def.limit){
mu = uniroot(function(mu){
thresholds = deltas*p + mu
default_rate_total(thresholds)-def.limit
}, lower=300,
upper=850)$root
mu+deltas*p
}
#Plot FICO by p
p_list = seq(-150, 50, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
#Find thresholds
for (p in p_list){
out[p-49,] = find.interp.thresholds(p/100, def.limit)
}
df = data.frame(out)
colnames(df) = c('asian','white','black','hispanic')
df$p = p_list
df = df %>% gather(key = 'race', value = 'FICO', 1:4)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race, linetype = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral"))+
ggtitle(paste("Def rate = ", def.limit, "\nBase rates = ", mu_type ))
#Find thresholds
for (p in p_list){
out[p+150,] = find.interp.thresholds(p/100, def.limit)
}
df = data.frame(out)
colnames(df) = c('asian','white','black','hispanic')
df$p = p_list
df = df %>% gather(key = 'race', value = 'FICO', 1:4)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race, linetype = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral"))+
ggtitle(paste("Def rate = ", def.limit, "\nBase rates = ", mu_type ))
#Plot FICO by p
p_list = seq(-150, 50, by = 1)
out = matrix(ncol = length(find.interp.thresholds(0.5, def.limit)),
nrow = length(p_list))
#Find thresholds
for (p in p_list){
out[p+151,] = find.interp.thresholds(p/100, def.limit)
}
df = data.frame(out)
colnames(df) = c('asian','white','black','hispanic')
df$p = p_list
df = df %>% gather(key = 'race', value = 'FICO', 1:4)
theme_set(theme_minimal())
ggplot(data = df, aes(x=p, y = FICO))+
geom_line(aes(color = race, linetype = race),size = 1)+
scale_color_manual(values=c("deepskyblue4", "firebrick2","lightseagreen","coral"))+
ggtitle(paste("Def rate = ", def.limit, "\nBase rates = ", mu_type ))
#Find approval percent
for (p in p_list){
for(i in 1:length(race_means))
out[p+151,i] = round((1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))*100,0)
#out[p+1,i] = (1-pnorm(find.interp.thresholds(p/100, def.limit)[i], race_means[i], race_sds[i]))
}
df = data.frame(out)
df$mu = rowMeans(df[,1:4])
colnames(df) = c('asian','white','black','hispanic', 'mu')
out.json = toJSON(df, pretty = T)
out.json
toJSON(rbind(fromJSON(step1), mu_type))
toJSON(rbind(fromJSON(out.json), mu_type))
toJSON(list(fromJSON(out.json), mu_type))
toJSON(list(fromJSON(out.json), mu_type, c(-150,50)))
library(tidyverse)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
stan = read.csv(file='D.txt')
glimpse(stan)
#to calculate correlations
cor.test(stan$mu, stan$C, method="kendall")
#Scatterplots of mu vs each variable
ggplot(stan, aes(x = mean.daily.p, y = mu )) +
geom_point(alpha = .03, size =2) +
theme_bw() +
theme(text = element_text(size=40), aspect.ratio=2/3)+
ylim(-17,-5)+
xlim(-17,-5)+
xlab("Observed Mean Log Prob")+
ylab('Mu')+
geom_smooth(method = 'lm')+
geom_abline(intercept = 0, color = 'red')
ggplot(stan, aes(x = mu, y = drift)) +
geom_point(alpha = .03, size =2) +
theme_bw() +
theme(text = element_text(size=40), aspect.ratio=2/3)+
ylim(0,1.5)+
ylab("Drift")+
xlab('Mu')
ggplot(stan, aes(x = mu, y = drift)) +
geom_hex(alpha = .03, size =2) +
theme_bw() +
theme(text = element_text(size=40), aspect.ratio=2/3)+
ylim(0,1.5)+
ylab("Drift")+
xlab('Mu')
ggplot(stan, aes(x = mu, y = drift)) +
geom_hex(alpha = 1, size =2) +
theme_bw() +
theme(text = element_text(size=40), aspect.ratio=2/3)+
ylim(0,1.5)+
ylab("Drift")+
xlab('Mu')
ggplot(stan, aes(x = mu, y = drift)) +
geom_hex(alpha = 1, size =1) +
theme_bw() +
theme(text = element_text(size=40), aspect.ratio=2/3)+
ylim(0,1.5)+
ylab("Drift")+
xlab('Mu')
ggplot(stan, aes(x = mu, y = drift)) +
geom_hex(alpha = 1, bins = 50) +
theme_bw() +
theme(text = element_text(size=40), aspect.ratio=2/3)+
ylim(0,1.5)+
ylab("Drift")+
xlab('Mu')
